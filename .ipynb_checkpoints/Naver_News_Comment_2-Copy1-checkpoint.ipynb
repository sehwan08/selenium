{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a518bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.common.exceptions import ElementClickInterceptedException, NoSuchElementException, ElementNotInteractableException  #(클릭시 없을때, 엘리멘트 자체가 없을떄, 엘리멘트가 상호작용을 못할때 )\n",
    "\n",
    "\n",
    "#웹브라우저를 띄우지 않고 진행하기 위한 설정\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5dd5de",
   "metadata": {},
   "source": [
    "### news_scraping() : 뉴스 스크래핑 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a661baa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_scraping(news_url, wd):\n",
    "    \n",
    "    press = wd.find_element(By.XPATH, '//*[@id=\"main_content\"]/div[1]/div[1]/a/img').get_attribute('title')\n",
    "    title = wd.find_element(By.ID, 'articleTitle').text\n",
    "    datetime = wd.find_element(By.CLASS_NAME, 't11').text\n",
    "    article = wd.find_element(By.ID, 'articleBodyContents').text\n",
    "    article = article.replace(\"// flash 오류를 우회하기 위한 함수 추가\", \"\")\n",
    "    article = article.replace(\"function _flash_removeCallback() {}\", \"\")\n",
    "    article = article.replace(\"\\n\", \"\")\n",
    "    article = article.replace(\"\\t\", \"\")\n",
    "    \n",
    "    good = wd.find_element(By.XPATH, '//*[@id=\"spiLayer\"]/div[1]/ul/li[1]/a/span[2]').text\n",
    "    warm = wd.find_element(By.XPATH, '//*[@id=\"spiLayer\"]/div[1]/ul/li[2]/a/span[2]').text\n",
    "    sad = wd.find_element(By.XPATH, '//*[@id=\"spiLayer\"]/div[1]/ul/li[3]/a/span[2]').text\n",
    "    angry = wd.find_element(By.XPATH, '//*[@id=\"spiLayer\"]/div[1]/ul/li[4]/a/span[2]').text\n",
    "    want = wd.find_element(By.XPATH, '//*[@id=\"spiLayer\"]/div[1]/ul/li[5]/a/span[2]').text\n",
    "    recommend = wd.find_element(By.XPATH, '//*[@id=\"toMainContainer\"]/a/em[2]').text\n",
    "    \n",
    "    print(\"뉴스: \", [title, press, datetime, article, good, warm, sad, angry, want, recommend, news_url])\n",
    "    \n",
    "    return [title, press, datetime, article, good, warm, sad, angry, want, recommend, news_url]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747301e7",
   "metadata": {},
   "source": [
    "### comments_scraping(): 뉴스 댓글 스크래핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3943947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comments_scraping(news_url, wd):\n",
    "    try:\n",
    "        btn_view = wd.find_element(By.CLASS_NAME, 'u_cbox_btn_view_comment').click() #댓글 더 보기\n",
    "        print(\"[댓글 더 보기]\", end=\"\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "        while True: #댓글 더보기 이후 더 보기를 계속 클릭해서 끝까지 가야하므로 while문을 써준다.\n",
    "            wd.find_element(By.CLASS_NAME,'u_cbox_page_more').click() #더 보기\n",
    "            print(\"[더 보기]\", end=\"\")\n",
    "            time.sleep(1)\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    btn_reply_list = wd.find_elements(By.CLASS_NAME, 'u_cbox_btn_reply') #답글 버튼 들고 옴\n",
    "    for btn_reply in btn_reply_list:\n",
    "        btn_reply.send_keys('\\n') #.click()으로 변화가 없는 부분은 이렇게 처리 한다.\n",
    "        print(\"[답글]\", end=\"\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "    print(\"[댓글 스크래핑]\")\n",
    "    \n",
    "    comments_idx = 0\n",
    "    comments_df = pd.DataFrame(columns=(\"Contents\",\"Name\",\"Datetime\",\"Like\",\"Dislike\",\"URL\"))\n",
    "    \n",
    "    \n",
    "    comments = wd.find_elements(By.CLASS_NAME, 'u_cbox_comment_box') #댓글 박스 들고 옴\n",
    "    for comment in comments:\n",
    "        try:\n",
    "            name = comment.find_element(By.CLASS_NAME, 'u_cbox_nick').text\n",
    "            date = comment.find_element(By.CLASS_NAME, 'u_cbox_date').text\n",
    "            contents = comment.find_element(By.CLASS_NAME, 'u_cbox_contents').text\n",
    "            recomm = comment.find_element(By.CLASS_NAME, 'u_cbox_cnt_recomm').text\n",
    "            unrecomm = comment.find_element(By.CLASS_NAME, 'u_cbox_cnt_unrecomm').text\n",
    "            print(f\"  댓글 #{comments_idx+1}:\", [contents, name, date, recomm, unrecomm, news_url])\n",
    "            comments_df.loc[comments_idx] = [contents, name, date, recomm, unrecomm, news_url]\n",
    "            comments_idx += 1\n",
    "        except NoSuchElementException:\n",
    "#             print(\"[삭제되거나 부적절한 댓글]\")\n",
    "            continue\n",
    "    \n",
    "    return comments_df\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4212ee",
   "metadata": {},
   "source": [
    "### scrpaing() : 스크래핑 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "317de291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping(news_max = 2):\n",
    "    wd = webdriver.Chrome('chromedriver', options=chrome_options)\n",
    "    wd.implicitly_wait(3) #대기 시간\n",
    "    \n",
    "    # --- 검색을 위한 세팅 ---\n",
    "    wd.execute_script('window.open(\"about:blank\", \"_blank\");') #JS의 새 탭을 띄우는 용도\n",
    "    tabs = wd.window_handles #탭 핸들링이 가능해 짐\n",
    "    wd.switch_to.window(tabs[0]) #첫번째 탭으로 전환\n",
    "    query = input(\"검색어 입력: \")\n",
    "    search_url = \"https://search.naver.com/search.naver?where=news&ie=utf8&sm=nws_hty&query=\" + query\n",
    "    wd.get(search_url)\n",
    "    \n",
    "    \n",
    "    # --- Data-Frame ---\n",
    "    news_idx = 0\n",
    "    news_df = pd.DataFrame(columns=(\"Title\",\"Press\",\"DateTime\",\"Article\",\"Good\",\"Warm\",\"Sad\",\"Angry\",\"Want\",\"Recommend\",\"URL\"))\n",
    "    comments_df = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # -- 검색 이후 '네이버 뉴스' 만 스크래핑 ---\n",
    "    while True:\n",
    "        info_list = wd.find_elements(By.CLASS_NAME, 'info_group')\n",
    "        for info in info_list:\n",
    "            first_step = info.find_elements(By.TAG_NAME, 'a')\n",
    "            try:\n",
    "                news_url = first_step[1].get_attribute('href') #'네이버 뉴스' 의 링크를 가져 옴\n",
    "                print(news_url)\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            wd.switch_to.window(tabs[1])\n",
    "            wd.get(news_url)\n",
    "\n",
    "            news_df.loc[news_idx] = news_scraping(news_url, wd)\n",
    "            news_idx += 1\n",
    "        \n",
    "            # --- 코멘트를 PD로 만들고 계속 합쳐서 만듬 ---\n",
    "            df = comments_scraping(news_url, wd)\n",
    "            comments_df = pd.concat([comments_df, df])\n",
    "            \n",
    "            if news_idx >= news_max:\n",
    "                break\n",
    "                \n",
    "        if news_idx >= news_max:\n",
    "            break\n",
    "                \n",
    "        \n",
    "        # --- 페이징 ---\n",
    "        try:\n",
    "            wd.switch_to.window(tabs[0]) #탭[1]에서 스크래핑이 다 끝나면 다시 텝[0]으로 돌아오고 다음 페이지로 이동 시킴\n",
    "            wd.find_element(By.CLASS_NAME, 'btn_next').click()\n",
    "            time.sleep(1)\n",
    "        except:\n",
    "            break\n",
    "    wd.close()\n",
    "    \n",
    "    return news_df, comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db0fd6ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색어 입력: 인공지능\n",
      "https://news.naver.com/main/read.naver?mode=LSD&mid=sec&sid1=105&oid=030&aid=0002993312\n",
      "뉴스:  ['코웨이 노블 정수기 품질, 인공지능이 인증했다', '전자신문', '2022.01.12. 오후 2:02', \"코웨이는 프리미엄 디자인 노블 정수기가 국내 최초로 'AI+(에이아이플러스)' 인공지능 품질 인증을 획득했다고 12일 밝혔다.코웨이 노블 정수기. [자료:코웨이]한국표준협회가 주관하는 AI+ 인증은 국내 유일 인공지능 품질 인증이다. 국제표준규격을 기반으로 인공지능 제품의 신뢰성·안전성 등에 대한 품질 수준을 평가해 인증한다.코웨이 노블 정수기 4종(빌트인, 가로, 세로, RO)은 품질경영시스템 국제표준규격(ISO 9001)에 대한 품질경영체계 현장 심사와 소프트웨어 품질 국제표준을 기반으로 제품 품질 및 사용자 관점 인공지능 기능을 평가하는 제품 시험을 모두 우수한 점수로 통과하며 해당 인증을 획득했다.코웨이 노블 정수기는 AI 기술을 활용해 제품 상태를 알아서 관리해 주는 '스마트 진단 기능'을 구현했다. 해당 기능은 제품 상태를 실시간으로 모니터링하고 이상 발견 시 해결 방법까지 안내해 준다.코웨이 관계자는 “코웨이 노블 정수기는 면밀한 소비자 사용 환경 분석 데이터를 기반으로 AI기술을 접목해 소비자에게 최적화된 사용 편의성을 제공하는 제품”이라며 “앞으로도 AI 등 디지털 기술을 더욱 고도화해 고객 가치 향상을 위한 제품과 서비스를 지속해 선보일 계획”이라고 말했다.\", '0', '0', '0', '0', '0', '', 'https://news.naver.com/main/read.naver?mode=LSD&mid=sec&sid1=105&oid=030&aid=0002993312']\n",
      "[댓글 스크래핑]\n"
     ]
    },
    {
     "ename": "StaleElementReferenceException",
     "evalue": "Message: stale element reference: element is not attached to the page document\n  (Session info: headless chrome=97.0.4692.71)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00AEFDC3+2555331]\n\tOrdinal0 [0x00A877F1+2127857]\n\tOrdinal0 [0x00982E08+1060360]\n\tOrdinal0 [0x00985524+1070372]\n\tOrdinal0 [0x009853EE+1070062]\n\tOrdinal0 [0x00985650+1070672]\n\tOrdinal0 [0x009AE212+1237522]\n\tOrdinal0 [0x009AE69B+1238683]\n\tOrdinal0 [0x009A4E71+1199729]\n\tOrdinal0 [0x009C7B54+1342292]\n\tOrdinal0 [0x009A4984+1198468]\n\tOrdinal0 [0x009C7C14+1342484]\n\tOrdinal0 [0x009D75FA+1406458]\n\tOrdinal0 [0x009C7976+1341814]\n\tOrdinal0 [0x009A36B6+1193654]\n\tOrdinal0 [0x009A4546+1197382]\n\tGetHandleVerifier [0x00C89622+1619522]\n\tGetHandleVerifier [0x00D3882C+2336844]\n\tGetHandleVerifier [0x00B823E1+541697]\n\tGetHandleVerifier [0x00B81443+537699]\n\tOrdinal0 [0x00A8D18E+2150798]\n\tOrdinal0 [0x00A91518+2168088]\n\tOrdinal0 [0x00A91660+2168416]\n\tOrdinal0 [0x00A9B330+2208560]\n\tBaseThreadInitThunk [0x774CFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77D27A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77D27A6E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStaleElementReferenceException\u001b[0m            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14376/2583452078.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnews_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomments_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscraping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14376/3782982499.py\u001b[0m in \u001b[0;36mscraping\u001b[1;34m(news_max)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0minfo_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'info_group'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minfo_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mfirst_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTAG_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mnews_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfirst_step\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#'네이버 뉴스' 의 링크를 가져 옴\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\devtools\\python\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36mfind_elements\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    742\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m         return self._execute(Command.FIND_CHILD_ELEMENTS,\n\u001b[0m\u001b[0;32m    745\u001b[0m                              {\"using\": by, \"value\": value})['value']\n\u001b[0;32m    746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\devtools\\python\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\devtools\\python\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    420\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mC:\\devtools\\python\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStaleElementReferenceException\u001b[0m: Message: stale element reference: element is not attached to the page document\n  (Session info: headless chrome=97.0.4692.71)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00AEFDC3+2555331]\n\tOrdinal0 [0x00A877F1+2127857]\n\tOrdinal0 [0x00982E08+1060360]\n\tOrdinal0 [0x00985524+1070372]\n\tOrdinal0 [0x009853EE+1070062]\n\tOrdinal0 [0x00985650+1070672]\n\tOrdinal0 [0x009AE212+1237522]\n\tOrdinal0 [0x009AE69B+1238683]\n\tOrdinal0 [0x009A4E71+1199729]\n\tOrdinal0 [0x009C7B54+1342292]\n\tOrdinal0 [0x009A4984+1198468]\n\tOrdinal0 [0x009C7C14+1342484]\n\tOrdinal0 [0x009D75FA+1406458]\n\tOrdinal0 [0x009C7976+1341814]\n\tOrdinal0 [0x009A36B6+1193654]\n\tOrdinal0 [0x009A4546+1197382]\n\tGetHandleVerifier [0x00C89622+1619522]\n\tGetHandleVerifier [0x00D3882C+2336844]\n\tGetHandleVerifier [0x00B823E1+541697]\n\tGetHandleVerifier [0x00B81443+537699]\n\tOrdinal0 [0x00A8D18E+2150798]\n\tOrdinal0 [0x00A91518+2168088]\n\tOrdinal0 [0x00A91660+2168416]\n\tOrdinal0 [0x00A9B330+2208560]\n\tBaseThreadInitThunk [0x774CFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77D27A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77D27A6E+238]\n"
     ]
    }
   ],
   "source": [
    "news_df, comments_df = scraping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01040cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8bf3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ebf799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc0beb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
